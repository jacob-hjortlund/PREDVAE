{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# n_cpu = os.cpu_count()\n",
    "# print(f\"Number of CPUs available: {n_cpu}\")\n",
    "# env_flag = f\"--xla_force_host_platform_device_count={n_cpu}\"\n",
    "# os.environ[\"XLA_FLAGS\"] = env_flag\n",
    "\n",
    "import jax\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "print(f\"JAX backend: {jax.devices()}\")\n",
    "\n",
    "import time\n",
    "import optax\n",
    "import hydra\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import src.predvae.nn as nn\n",
    "import src.predvae.data as data\n",
    "import src.predvae.training as training\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from jax.tree_util import tree_map\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "with initialize(version_base=None, config_path=\"config\"):\n",
    "        cfg = compose(config_name=\"config\")\n",
    "        print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(cfg[\"data_config\"][\"data_dir\"])\n",
    "SAVE_DIR = Path(cfg[\"save_dir\"]) / cfg[\"run_name\"]\n",
    "SAVE_DIR.mkdir(exist_ok=True, parents=True)\n",
    "RNG_KEY = jax.random.PRNGKey(cfg[\"seed\"])\n",
    "\n",
    "# ----------------------------- LOAD DATA -----------------------------\n",
    "\n",
    "print(\n",
    "    \"\\n--------------------------------- LOADING DATA ---------------------------------\\n\"\n",
    ")\n",
    "\n",
    "spec_df = pd.read_csv(\n",
    "    DATA_DIR / cfg[\"data_config\"][\"spec_file\"],\n",
    "    # nrows=cfg[\"training_config\"][\"batch_size\"] * 11,\n",
    ")\n",
    "photo_df = pd.read_csv(\n",
    "    DATA_DIR / cfg[\"data_config\"][\"photo_file\"],\n",
    "    skiprows=[1],\n",
    "    # nrows=cfg[\"training_config\"][\"batch_size\"] * 11,\n",
    ")\n",
    "\n",
    "# ----------------------------- RESET BATCH SIZES AND ALPHA -----------------------------\n",
    "\n",
    "n_spec = spec_df.shape[0]\n",
    "n_photo = photo_df.shape[0]\n",
    "spec_ratio = n_spec / (n_spec + n_photo)\n",
    "\n",
    "PHOTOMETRIC_BATCH_SIZE = np.round(\n",
    "    cfg[\"training_config\"][\"batch_size\"] * (1 - spec_ratio)\n",
    ").astype(int)\n",
    "SPECTROSCOPIC_BATCH_SIZE = (\n",
    "    cfg[\"training_config\"][\"batch_size\"] - PHOTOMETRIC_BATCH_SIZE\n",
    ")\n",
    "ALPHA = (\n",
    "    PHOTOMETRIC_BATCH_SIZE + SPECTROSCOPIC_BATCH_SIZE\n",
    ") * SPECTROSCOPIC_BATCH_SIZE\n",
    "batch_size_ratio = SPECTROSCOPIC_BATCH_SIZE / (\n",
    "    SPECTROSCOPIC_BATCH_SIZE + PHOTOMETRIC_BATCH_SIZE\n",
    ")\n",
    "expected_no_of_spec_batches = n_spec // SPECTROSCOPIC_BATCH_SIZE\n",
    "expected_no_of_photo_batches = n_photo // PHOTOMETRIC_BATCH_SIZE\n",
    "\n",
    "print(f\"\\nN Spec: {n_spec}\")\n",
    "print(f\"N Photo: {n_photo}\")\n",
    "print(f\"Spec Ratio: {spec_ratio}\")\n",
    "print(f\"Batch Size: {cfg['training_config']['batch_size']}\")\n",
    "print(f\"Photometric Batch Size: {PHOTOMETRIC_BATCH_SIZE}\")\n",
    "print(f\"Spectroscopic Batch Size: {SPECTROSCOPIC_BATCH_SIZE}\")\n",
    "print(f\"Batch Size Ratio: {batch_size_ratio}\")\n",
    "print(f\"Expected No of Spec Batches: {expected_no_of_spec_batches}\")\n",
    "print(f\"Expected No of Photo Batches: {expected_no_of_photo_batches}\\n\")\n",
    "\n",
    "# ----------------------------- CREATE INPUT ARRAYS -----------------------------\n",
    "\n",
    "(\n",
    "    spec_psf_photometry,\n",
    "    spec_psf_photometry_err,\n",
    "    spec_model_photometry,\n",
    "    spec_model_photometry_err,\n",
    "    spec_additional_info,\n",
    "    spec_z,\n",
    "    spec_objid,\n",
    ") = data.create_input_arrays(\n",
    "    input_df=spec_df,\n",
    "    psf_columns=cfg[\"data_config\"][\"psf_columns\"],\n",
    "    psf_err_columns=cfg[\"data_config\"][\"psf_err_columns\"],\n",
    "    model_columns=cfg[\"data_config\"][\"model_columns\"],\n",
    "    model_err_columns=cfg[\"data_config\"][\"model_err_columns\"],\n",
    "    additional_columns=cfg[\"data_config\"][\"additional_columns\"],\n",
    "    z_column=cfg[\"data_config\"][\"z_column\"],\n",
    "    objid_column=cfg[\"data_config\"][\"objid_column\"],\n",
    "    shuffle=cfg[\"data_config\"][\"shuffle\"],\n",
    ")\n",
    "spec_psf_photometry = spec_psf_photometry.squeeze(axis=0)\n",
    "spec_psf_photometry_err = spec_psf_photometry_err.squeeze(axis=0)\n",
    "spec_model_photometry = spec_model_photometry.squeeze(axis=0)\n",
    "spec_model_photometry_err = spec_model_photometry_err.squeeze(axis=0)\n",
    "spec_additional_info = jnp.log10(spec_additional_info).squeeze(axis=0)\n",
    "spec_z = jnp.log10(spec_z).squeeze(axis=0)\n",
    "spec_objid = spec_objid.squeeze(axis=0)\n",
    "\n",
    "(\n",
    "    photo_psf_photometry,\n",
    "    photo_psf_photometry_err,\n",
    "    photo_model_photometry,\n",
    "    photo_model_photometry_err,\n",
    "    photo_additional_info,\n",
    "    _,\n",
    "    photo_objid,\n",
    ") = data.create_input_arrays(\n",
    "    input_df=photo_df,\n",
    "    psf_columns=cfg[\"data_config\"][\"psf_columns\"],\n",
    "    psf_err_columns=cfg[\"data_config\"][\"psf_err_columns\"],\n",
    "    model_columns=cfg[\"data_config\"][\"model_columns\"],\n",
    "    model_err_columns=cfg[\"data_config\"][\"model_err_columns\"],\n",
    "    additional_columns=cfg[\"data_config\"][\"additional_columns\"],\n",
    "    z_column=None,\n",
    "    objid_column=cfg[\"data_config\"][\"objid_column\"],\n",
    "    shuffle=cfg[\"data_config\"][\"shuffle\"],\n",
    ")\n",
    "photo_psf_photometry = photo_psf_photometry.squeeze(axis=0)\n",
    "photo_psf_photometry_err = photo_psf_photometry_err.squeeze(axis=0)\n",
    "photo_model_photometry = photo_model_photometry.squeeze(axis=0)\n",
    "photo_model_photometry_err = photo_model_photometry_err.squeeze(axis=0)\n",
    "photo_additional_info = jnp.log10(photo_additional_info).squeeze(axis=0)\n",
    "photo_objid = photo_objid.squeeze(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- SPLIT INTO TRAIN AND VAL -----------------------------\n",
    "\n",
    "spec_split_key, photo_split_key, RNG_KEY = jr.split(RNG_KEY, 3)\n",
    "spec_val_mask = jax.random.bernoulli(\n",
    "    spec_split_key,\n",
    "    p=cfg[\"data_config\"][\"validation_fraction\"],\n",
    "    shape=(spec_z.shape[0],),\n",
    ")\n",
    "photo_val_mask = jax.random.bernoulli(\n",
    "    photo_split_key,\n",
    "    p=cfg[\"data_config\"][\"validation_fraction\"],\n",
    "    shape=(photo_objid.shape[0],),\n",
    ")\n",
    "\n",
    "spec_psf_photometry_train = spec_psf_photometry[~spec_val_mask]\n",
    "spec_psf_photometry_err_train = spec_psf_photometry_err[~spec_val_mask]\n",
    "spec_model_photometry_train = spec_model_photometry[~spec_val_mask]\n",
    "spec_model_photometry_err_train = spec_model_photometry_err[~spec_val_mask]\n",
    "spec_additional_info_train = spec_additional_info[~spec_val_mask]\n",
    "spec_z_train = spec_z[~spec_val_mask]\n",
    "spec_objid_train = spec_objid[~spec_val_mask]\n",
    "\n",
    "spec_psf_photometry_val = spec_psf_photometry[spec_val_mask]\n",
    "spec_psf_photometry_err_val = spec_psf_photometry_err[spec_val_mask]\n",
    "spec_model_photometry_val = spec_model_photometry[spec_val_mask]\n",
    "spec_model_photometry_err_val = spec_model_photometry_err[spec_val_mask]\n",
    "spec_additional_info_val = spec_additional_info[spec_val_mask]\n",
    "spec_z_val = spec_z[spec_val_mask]\n",
    "spec_objid_val = spec_objid[spec_val_mask]\n",
    "\n",
    "photo_psf_photometry_train = photo_psf_photometry[~photo_val_mask]\n",
    "photo_psf_photometry_err_train = photo_psf_photometry_err[~photo_val_mask]\n",
    "photo_model_photometry_train = photo_model_photometry[~photo_val_mask]\n",
    "photo_model_photometry_err_train = photo_model_photometry_err[~photo_val_mask]\n",
    "photo_additional_info_train = photo_additional_info[~photo_val_mask]\n",
    "photo_objid_train = photo_objid[~photo_val_mask]\n",
    "\n",
    "photo_psf_photometry_val = photo_psf_photometry[photo_val_mask]\n",
    "photo_psf_photometry_err_val = photo_psf_photometry_err[photo_val_mask]\n",
    "photo_model_photometry_val = photo_model_photometry[photo_val_mask]\n",
    "photo_model_photometry_err_val = photo_model_photometry_err[photo_val_mask]\n",
    "photo_additional_info_val = photo_additional_info[photo_val_mask]\n",
    "photo_objid_val = photo_objid[photo_val_mask]\n",
    "\n",
    "n_train_spec = spec_psf_photometry_train.shape[0]\n",
    "n_train_photo = photo_psf_photometry_train.shape[0]\n",
    "n_val_spec = spec_psf_photometry_val.shape[0]\n",
    "n_val_photo = photo_psf_photometry_val.shape[0]\n",
    "\n",
    "expected_n_train_spec_batches = n_train_spec // SPECTROSCOPIC_BATCH_SIZE\n",
    "expected_n_train_photo_batches = n_train_photo // PHOTOMETRIC_BATCH_SIZE\n",
    "expected_n_val_spec_batches = n_val_spec // SPECTROSCOPIC_BATCH_SIZE\n",
    "expected_n_val_photo_batches = n_val_photo // PHOTOMETRIC_BATCH_SIZE\n",
    "\n",
    "print(f\"\\nTrain Spec: {spec_psf_photometry_train.shape[0]}\")\n",
    "print(f\"Train Photo: {photo_psf_photometry_train.shape[0]}\")\n",
    "print(\n",
    "    f\"Expected No of Train Batches: {expected_n_train_spec_batches} / {expected_n_train_photo_batches}\\n\"\n",
    ")\n",
    "\n",
    "print(f\"\\nVal Spec: {spec_psf_photometry_val.shape[0]}\")\n",
    "print(f\"Val Photo: {photo_psf_photometry_val.shape[0]}\")\n",
    "print(\n",
    "    f\"Expected No of Val Batches: {expected_n_val_spec_batches} / {expected_n_val_photo_batches}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec_dataset = data.SpectroPhotometricDataset(\n",
    "    spec_psf_photometry_train,\n",
    "    spec_psf_photometry_err_train,\n",
    "    spec_model_photometry_train,\n",
    "    spec_model_photometry_err_train,\n",
    "    spec_additional_info_train,\n",
    "    spec_z_train,\n",
    "    spec_objid_train,\n",
    ")\n",
    "\n",
    "train_photo_dataset = data.SpectroPhotometricDataset(\n",
    "    photo_psf_photometry_train,\n",
    "    photo_psf_photometry_err_train,\n",
    "    photo_model_photometry_train,\n",
    "    photo_model_photometry_err_train,\n",
    "    photo_additional_info_train,\n",
    "    None,\n",
    "    photo_objid_train,\n",
    ")\n",
    "\n",
    "train_dataset_statistics = data.SpectroPhotometricStatistics(\n",
    "    train_photo_dataset, train_spec_dataset\n",
    ")\n",
    "\n",
    "training.save(SAVE_DIR / \"train_dataset_statistics.pkl\", train_dataset_statistics)\n",
    "\n",
    "val_spec_dataset = data.SpectroPhotometricDataset(\n",
    "    spec_psf_photometry_val,\n",
    "    spec_psf_photometry_err_val,\n",
    "    spec_model_photometry_val,\n",
    "    spec_model_photometry_err_val,\n",
    "    spec_additional_info_val,\n",
    "    spec_z_val,\n",
    "    spec_objid_val,\n",
    ")\n",
    "\n",
    "val_photo_dataset = data.SpectroPhotometricDataset(\n",
    "    photo_psf_photometry_val,\n",
    "    photo_psf_photometry_err_val,\n",
    "    photo_model_photometry_val,\n",
    "    photo_model_photometry_err_val,\n",
    "    photo_additional_info_val,\n",
    "    None,\n",
    "    photo_objid_val,\n",
    ")\n",
    "\n",
    "val_dataset_statistics = data.SpectroPhotometricStatistics(\n",
    "    val_photo_dataset, val_spec_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    predictor_key,\n",
    "    encoder_input_key,\n",
    "    encoder_key,\n",
    "    decoder_input_key,\n",
    "    decoder_key,\n",
    "    RNG_KEY,\n",
    ") = jr.split(RNG_KEY, 6)\n",
    "\n",
    "decoder_input_layer = nn.InputLayer(\n",
    "    x_features=cfg[\"model_config\"][\"latent_size\"],\n",
    "    y_features=cfg[\"model_config\"][\"predictor_size\"],\n",
    "    out_features=cfg[\"model_config\"][\"latent_size\"]\n",
    "    + cfg[\"model_config\"][\"predictor_size\"],\n",
    "    key=decoder_input_key,\n",
    ")\n",
    "\n",
    "decoder = nn.GaussianCoder(\n",
    "    input_size=cfg[\"model_config\"][\"latent_size\"]\n",
    "    + cfg[\"model_config\"][\"predictor_size\"],\n",
    "    output_size=cfg[\"model_config\"][\"input_size\"],\n",
    "    width=cfg[\"model_config\"][\"layers\"],\n",
    "    depth=len(cfg[\"model_config\"][\"layers\"]),\n",
    "    activation=getattr(jax.nn, cfg[\"model_config\"][\"activation\"]),\n",
    "    key=decoder_key,\n",
    "    use_spectral_norm=cfg[\"model_config\"][\"use_spec_norm\"],\n",
    "    use_final_spectral_norm=cfg[\"model_config\"][\"use_final_spec_norm\"],\n",
    "    num_power_iterations=cfg[\"model_config\"][\"num_power_iterations\"],\n",
    ")\n",
    "\n",
    "latent_prior = nn.Gaussian(\n",
    "    mu=jnp.zeros(cfg[\"model_config\"][\"latent_size\"]),\n",
    "    log_sigma=jnp.zeros(cfg[\"model_config\"][\"latent_size\"]),\n",
    ")\n",
    "\n",
    "target_prior = nn.Gaussian(\n",
    "    mu=jnp.zeros(cfg[\"model_config\"][\"predictor_size\"]),\n",
    "    log_sigma=jnp.zeros(cfg[\"model_config\"][\"predictor_size\"]),\n",
    ")\n",
    "\n",
    "if cfg[\"model_config\"][\"use_v2\"]:\n",
    "\n",
    "    encoder = nn.GaussianCoder(\n",
    "        input_size=cfg[\"model_config\"][\"input_size\"],\n",
    "        output_size=cfg[\"model_config\"][\"latent_size\"],\n",
    "        width=cfg[\"model_config\"][\"layers\"],\n",
    "        depth=len(cfg[\"model_config\"][\"layers\"]),\n",
    "        activation=getattr(jax.nn, cfg[\"model_config\"][\"activation\"]),\n",
    "        key=encoder_key,\n",
    "        use_spectral_norm=cfg[\"model_config\"][\"use_spec_norm\"],\n",
    "        use_final_spectral_norm=cfg[\"model_config\"][\"use_final_spec_norm\"],\n",
    "        num_power_iterations=cfg[\"model_config\"][\"num_power_iterations\"],\n",
    "    )\n",
    "\n",
    "    predictor_input_layer = nn.InputLayer(\n",
    "        x_features=cfg[\"model_config\"][\"latent_size\"],\n",
    "        y_features=cfg[\"model_config\"][\"input_size\"],\n",
    "        out_features=cfg[\"model_config\"][\"latent_size\"]\n",
    "        + cfg[\"model_config\"][\"input_size\"],\n",
    "        key=encoder_input_key,\n",
    "    )\n",
    "\n",
    "    predictor = nn.GaussianMixtureCoder(\n",
    "        input_size=cfg[\"model_config\"][\"latent_size\"]\n",
    "        + cfg[\"model_config\"][\"input_size\"],\n",
    "        output_size=cfg[\"model_config\"][\"predictor_size\"],\n",
    "        width=cfg[\"model_config\"][\"layers\"],\n",
    "        depth=len(cfg[\"model_config\"][\"layers\"]),\n",
    "        num_components=cfg[\"model_config\"][\"num_mixture_components\"],\n",
    "        activation=getattr(jax.nn, cfg[\"model_config\"][\"activation\"]),\n",
    "        key=predictor_key,\n",
    "        use_spectral_norm=cfg[\"model_config\"][\"use_spec_norm\"],\n",
    "        use_final_spectral_norm=cfg[\"model_config\"][\"use_final_spec_norm\"],\n",
    "        num_power_iterations=cfg[\"model_config\"][\"num_power_iterations\"],\n",
    "    )\n",
    "\n",
    "    SSVAE = partial(\n",
    "        nn.SSVAEv2,\n",
    "        encoder=encoder,\n",
    "        predictor=predictor,\n",
    "        predictor_input_layer=predictor_input_layer,\n",
    "    )\n",
    "\n",
    "else:\n",
    "\n",
    "    encoder_input_layer = nn.InputLayer(\n",
    "        x_features=cfg[\"model_config\"][\"input_size\"],\n",
    "        y_features=cfg[\"model_config\"][\"predictor_size\"],\n",
    "        out_features=cfg[\"model_config\"][\"input_size\"]\n",
    "        + cfg[\"model_config\"][\"predictor_size\"],\n",
    "        key=encoder_input_key,\n",
    "    )\n",
    "\n",
    "    encoder = nn.GaussianCoder(\n",
    "        input_size=cfg[\"model_config\"][\"input_size\"]\n",
    "        + cfg[\"model_config\"][\"predictor_size\"],\n",
    "        output_size=cfg[\"model_config\"][\"latent_size\"],\n",
    "        width=cfg[\"model_config\"][\"layers\"],\n",
    "        depth=len(cfg[\"model_config\"][\"layers\"]),\n",
    "        activation=getattr(jax.nn, cfg[\"model_config\"][\"activation\"]),\n",
    "        key=encoder_key,\n",
    "        use_spectral_norm=cfg[\"model_config\"][\"use_spec_norm\"],\n",
    "        use_final_spectral_norm=cfg[\"model_config\"][\"use_final_spec_norm\"],\n",
    "        num_power_iterations=cfg[\"model_config\"][\"num_power_iterations\"],\n",
    "    )\n",
    "\n",
    "    predictor = nn.GaussianMixtureCoder(\n",
    "        input_size=cfg[\"model_config\"][\"input_size\"],\n",
    "        output_size=cfg[\"model_config\"][\"predictor_size\"],\n",
    "        width=cfg[\"model_config\"][\"layers\"],\n",
    "        depth=len(cfg[\"model_config\"][\"layers\"]),\n",
    "        num_components=cfg[\"model_config\"][\"num_mixture_components\"],\n",
    "        activation=getattr(jax.nn, cfg[\"model_config\"][\"activation\"]),\n",
    "        key=predictor_key,\n",
    "        use_spectral_norm=cfg[\"model_config\"][\"use_spec_norm\"],\n",
    "        use_final_spectral_norm=cfg[\"model_config\"][\"use_final_spec_norm\"],\n",
    "        num_power_iterations=cfg[\"model_config\"][\"num_power_iterations\"],\n",
    "    )\n",
    "\n",
    "    SSVAE = partial(\n",
    "        nn.SSVAE,\n",
    "        encoder=encoder,\n",
    "        predictor=predictor,\n",
    "        encoder_input_layer=encoder_input_layer,\n",
    "    )\n",
    "\n",
    "ssvae, input_state = eqx.nn.make_with_state(SSVAE)(\n",
    "    decoder=decoder,\n",
    "    latent_prior=latent_prior,\n",
    "    target_prior=target_prior,\n",
    "    decoder_input_layer=decoder_input_layer,\n",
    ")\n",
    "\n",
    "training.save(SAVE_DIR / \"initial_model.pkl\", ssvae)\n",
    "filter_spec = tree_map(lambda _: True, ssvae)\n",
    "filter_spec = nn.freeze_prior(ssvae, space=\"latent\", filter_spec=filter_spec)\n",
    "\n",
    "train_loss = []\n",
    "train_aux = []\n",
    "val_loss = []\n",
    "val_aux = []\n",
    "best_val_loss = jnp.inf\n",
    "best_val_epoch = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg[\"training_config\"][\"pretrain_vae\"]:\n",
    "\n",
    "    ###################################################################################\n",
    "    ################################# DATALOADERS #####################################\n",
    "    ###################################################################################\n",
    "\n",
    "    train_photo_dataloader_key, train_spec_dataloader_key, RNG_KEY = jr.split(\n",
    "        RNG_KEY, 3\n",
    "    )\n",
    "\n",
    "    (\n",
    "        train_photometric_dataloader,\n",
    "        train_photometric_dataloader_state,\n",
    "    ) = data.make_dataloader(\n",
    "        train_photo_dataset,\n",
    "        batch_size=PHOTOMETRIC_BATCH_SIZE,\n",
    "        rng_key=train_photo_dataloader_key,\n",
    "        shuffle=cfg[\"data_config\"][\"shuffle\"],\n",
    "        drop_last=cfg[\"data_config\"][\"drop_last\"],\n",
    "    )\n",
    "\n",
    "    (\n",
    "        train_spectroscopic_dataloader,\n",
    "        train_spectroscopic_dataloader_state,\n",
    "    ) = data.make_dataloader(\n",
    "        train_spec_dataset,\n",
    "        batch_size=SPECTROSCOPIC_BATCH_SIZE,\n",
    "        rng_key=train_spec_dataloader_key,\n",
    "        shuffle=cfg[\"data_config\"][\"shuffle\"],\n",
    "        drop_last=cfg[\"data_config\"][\"drop_last\"],\n",
    "    )\n",
    "\n",
    "    train_iterator = data.make_spectrophotometric_iterator(\n",
    "        train_photometric_dataloader,\n",
    "        train_spectroscopic_dataloader,\n",
    "        train_dataset_statistics,\n",
    "        resample_photometry=cfg[\"data_config\"][\"resample_photometry\"],\n",
    "    )\n",
    "\n",
    "    val_photo_dataloader_key, val_spec_dataloader_key, RNG_KEY = jr.split(\n",
    "        RNG_KEY, 3\n",
    "    )\n",
    "\n",
    "    (\n",
    "        val_photometric_dataloader,\n",
    "        val_photometric_dataloader_state,\n",
    "    ) = data.make_dataloader(\n",
    "        val_photo_dataset,\n",
    "        batch_size=PHOTOMETRIC_BATCH_SIZE,\n",
    "        rng_key=val_photo_dataloader_key,\n",
    "        shuffle=False,\n",
    "        drop_last=cfg[\"data_config\"][\"drop_last\"],\n",
    "    )\n",
    "\n",
    "    (\n",
    "        val_spectroscopic_dataloader,\n",
    "        val_spectroscopic_dataloader_state,\n",
    "    ) = data.make_dataloader(\n",
    "        val_spec_dataset,\n",
    "        batch_size=SPECTROSCOPIC_BATCH_SIZE,\n",
    "        rng_key=val_spec_dataloader_key,\n",
    "        shuffle=False,\n",
    "        drop_last=cfg[\"data_config\"][\"drop_last\"],\n",
    "    )\n",
    "\n",
    "    val_iterator = data.make_spectrophotometric_iterator(\n",
    "        val_photometric_dataloader,\n",
    "        val_spectroscopic_dataloader,\n",
    "        val_dataset_statistics,\n",
    "        resample_photometry=cfg[\"data_config\"][\"resample_photometry\"],\n",
    "    )\n",
    "\n",
    "    val_step_time = 0\n",
    "    train_step_time = 0\n",
    "    epoch_time = 0\n",
    "\n",
    "    filter_spec = nn.freeze_prior(ssvae, space=\"target\", filter_spec=filter_spec)\n",
    "    filter_spec = nn.freeze_submodule(ssvae, \"predictor\", filter_spec=filter_spec)\n",
    "    filter_spec = nn.freeze_submodule_inputs(\n",
    "        ssvae, \"decoder\", freeze_x=False, freeze_y=True, filter_spec=filter_spec\n",
    "    )\n",
    "    ssvae = nn.init_submodule_inputs(\n",
    "        ssvae, \"decoder\", RNG_KEY, init_x=False, init_y=True, init_value=0.0\n",
    "    )\n",
    "    ssvae = nn.set_submodule_inference_mode(ssvae, \"predictor\", True)\n",
    "\n",
    "    if cfg[\"model_config\"][\"use_v2\"]:\n",
    "        filter_spec = nn.freeze_submodule_inputs(\n",
    "            ssvae,\n",
    "            \"predictor\",\n",
    "            freeze_x=True,\n",
    "            freeze_y=True,\n",
    "            filter_spec=filter_spec,\n",
    "        )\n",
    "    else:\n",
    "        filter_spec = nn.freeze_submodule_inputs(\n",
    "            ssvae, \"encoder\", freeze_x=False, freeze_y=True, filter_spec=filter_spec\n",
    "        )\n",
    "        ssvae = nn.init_submodule_inputs(\n",
    "            ssvae, \"encoder\", RNG_KEY, init_x=False, init_y=True, init_value=0.0\n",
    "        )\n",
    "\n",
    "    lr_schedule = optax.warmup_cosine_decay_schedule(\n",
    "        cfg[\"training_config\"][\"final_lr\"],\n",
    "        cfg[\"training_config\"][\"init_lr\"],\n",
    "        cfg[\"training_config\"][\"warmup\"],\n",
    "        cfg[\"training_config\"][\"vae_epochs\"] - cfg[\"training_config\"][\"warmup\"],\n",
    "        cfg[\"training_config\"][\"final_lr\"],\n",
    "    )\n",
    "    optimizer = optax.adam(learning_rate=lr_schedule)\n",
    "    optimizer_state = optimizer.init(eqx.filter(ssvae, eqx.is_array))\n",
    "\n",
    "    loss_kwargs = {\n",
    "        \"alpha\": ALPHA,\n",
    "        \"missing_target_value\": cfg[\"data_config\"][\"missing_target_value\"],\n",
    "        \"vae_factor\": 1.0,\n",
    "        \"beta\": cfg[\"training_config\"][\"beta\"],\n",
    "        \"predictor_factor\": 0.0,\n",
    "        \"target_factor\": 0.0,\n",
    "        \"n_samples\": cfg[\"training_config\"][\"n_mc_samples\"],\n",
    "    }\n",
    "    pretrain_vae_loss_fn = partial(training.ssvae_loss, **loss_kwargs)\n",
    "\n",
    "    _train_step = training.make_train_step(\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=pretrain_vae_loss_fn,\n",
    "        filter_spec=filter_spec,\n",
    "    )\n",
    "\n",
    "    _val_step = training.make_eval_step(\n",
    "        loss_fn=pretrain_vae_loss_fn,\n",
    "        filter_spec=filter_spec,\n",
    "    )\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def train_step(\n",
    "        ssvae, ssvae_state, optimizer_state, photo_dl_state, spec_dl_state, rng_key\n",
    "    ):\n",
    "\n",
    "        resampling_key, step_key = jr.split(rng_key)\n",
    "\n",
    "        (\n",
    "            x,\n",
    "            y,\n",
    "            photo_dl_state,\n",
    "            spec_dl_state,\n",
    "            _,\n",
    "            spectroscopic_reset_condition,\n",
    "        ) = train_iterator(\n",
    "            photo_dl_state,\n",
    "            spec_dl_state,\n",
    "            resampling_key,\n",
    "        )\n",
    "\n",
    "        end_of_split = jnp.all(spectroscopic_reset_condition)\n",
    "\n",
    "        ssvae, ssvae_state, optimizer_state, loss_value, loss_aux = _train_step(\n",
    "            x,\n",
    "            y,\n",
    "            step_key,\n",
    "            ssvae,\n",
    "            ssvae_state,\n",
    "            optimizer_state,\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            loss_value,\n",
    "            loss_aux,\n",
    "            ssvae,\n",
    "            ssvae_state,\n",
    "            optimizer_state,\n",
    "            photo_dl_state,\n",
    "            spec_dl_state,\n",
    "            end_of_split,\n",
    "        )\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def eval_step(\n",
    "        ssvae,\n",
    "        ssvae_state,\n",
    "        train_photo_dl_state,\n",
    "        train_spec_dl_state,\n",
    "        val_photo_dl_state,\n",
    "        val_spec_dl_state,\n",
    "        rng_key,\n",
    "    ):\n",
    "\n",
    "        train_resampling_key, val_resampling_key, rng_key = jr.split(rng_key, 3)\n",
    "        train_step_key, val_step_key = jr.split(rng_key)\n",
    "\n",
    "        (\n",
    "            x_val_split,\n",
    "            y_val_split,\n",
    "            val_photo_dl_state,\n",
    "            val_spec_dl_state,\n",
    "            photometric_reset_condition,\n",
    "            spectroscopic_reset_condition,\n",
    "        ) = val_iterator(\n",
    "            val_photo_dl_state,\n",
    "            val_spec_dl_state,\n",
    "            val_resampling_key,\n",
    "        )\n",
    "\n",
    "        (\n",
    "            x_train_split,\n",
    "            y_train_split,\n",
    "            train_photo_dl_state,\n",
    "            train_spec_dl_state,\n",
    "            _,\n",
    "            _,\n",
    "        ) = train_iterator(\n",
    "            train_photo_dl_state,\n",
    "            train_spec_dl_state,\n",
    "            train_resampling_key,\n",
    "        )\n",
    "\n",
    "        (\n",
    "            train_loss_value,\n",
    "            ssvae_state,\n",
    "            train_loss_aux,\n",
    "        ) = _val_step(\n",
    "            x_train_split,\n",
    "            y_train_split,\n",
    "            train_step_key,\n",
    "            ssvae,\n",
    "            ssvae_state,\n",
    "        )\n",
    "\n",
    "        val_loss_value, input_state, val_loss_aux = _val_step(\n",
    "            x_val_split,\n",
    "            y_val_split,\n",
    "            val_step_key,\n",
    "            ssvae,\n",
    "            ssvae_state,\n",
    "        )\n",
    "\n",
    "        end_of_val_split = jnp.all(spectroscopic_reset_condition)\n",
    "\n",
    "        return (\n",
    "            train_loss_value,\n",
    "            train_loss_aux,\n",
    "            val_loss_value,\n",
    "            val_loss_aux,\n",
    "            input_state,\n",
    "            train_photo_dl_state,\n",
    "            train_spec_dl_state,\n",
    "            val_photo_dl_state,\n",
    "            val_spec_dl_state,\n",
    "            end_of_val_split,\n",
    "        )\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    for epoch in range(cfg[\"training_config\"][\"vae_epochs\"]):\n",
    "\n",
    "        end_of_train_split = False\n",
    "        end_of_val_split = False\n",
    "\n",
    "        train_batches = 0\n",
    "        val_batches = 0\n",
    "        epoch_train_loss = []\n",
    "        epoch_train_aux = []\n",
    "        epoch_val_loss = []\n",
    "        epoch_val_aux = []\n",
    "\n",
    "        t0_epoch = time.time()\n",
    "\n",
    "        epoch_train_key, epoch_val_key, RNG_KEY = jr.split(RNG_KEY, 3)\n",
    "\n",
    "        while not end_of_train_split:\n",
    "\n",
    "            step_key, epoch_train_key = jr.split(epoch_train_key)\n",
    "\n",
    "            (\n",
    "                batch_train_loss,\n",
    "                batch_train_aux,\n",
    "                ssvae,\n",
    "                input_state,\n",
    "                optimizer_state,\n",
    "                train_photometric_dataloader_state,\n",
    "                train_spectroscopic_dataloader_state,\n",
    "                end_of_train_split,\n",
    "            ) = train_step(\n",
    "                ssvae,\n",
    "                input_state,\n",
    "                optimizer_state,\n",
    "                train_photometric_dataloader_state,\n",
    "                train_spectroscopic_dataloader_state,\n",
    "                step_key,\n",
    "            )\n",
    "\n",
    "            if end_of_train_split:\n",
    "                break\n",
    "\n",
    "            train_batches += 1\n",
    "\n",
    "        t1 = time.time()\n",
    "        train_step_time += t1 - t0_epoch\n",
    "\n",
    "        inference_ssvae = eqx.nn.inference_mode(ssvae)\n",
    "\n",
    "        t0_val = time.time()\n",
    "        while not end_of_val_split:\n",
    "\n",
    "            t0_single = time.time()\n",
    "\n",
    "            val_step_key, epoch_val_key = jr.split(epoch_val_key)\n",
    "\n",
    "            (\n",
    "                batch_train_loss,\n",
    "                batch_train_aux,\n",
    "                batch_val_loss,\n",
    "                batch_val_aux,\n",
    "                input_state,\n",
    "                train_photometric_dataloader_state,\n",
    "                train_spectroscopic_dataloader_state,\n",
    "                val_photometric_dataloader_state,\n",
    "                val_spectroscopic_dataloader_state,\n",
    "                end_of_val_split,\n",
    "            ) = eval_step(\n",
    "                inference_ssvae,\n",
    "                input_state,\n",
    "                train_photometric_dataloader_state,\n",
    "                train_spectroscopic_dataloader_state,\n",
    "                val_photometric_dataloader_state,\n",
    "                val_spectroscopic_dataloader_state,\n",
    "                val_step_key,\n",
    "            )\n",
    "\n",
    "            if end_of_val_split:\n",
    "                break\n",
    "\n",
    "            epoch_train_loss.append(batch_train_loss)\n",
    "            epoch_train_aux.append(batch_train_aux)\n",
    "            epoch_val_loss.append(batch_val_loss)\n",
    "            epoch_val_aux.append(batch_val_aux)\n",
    "\n",
    "            val_batches += 1\n",
    "            t1_single = time.time()\n",
    "\n",
    "        train_photometric_dataloader_state = train_photometric_dataloader_state.set(\n",
    "            train_photometric_dataloader.reset_index, jnp.array(True)\n",
    "        )\n",
    "        train_spectroscopic_dataloader_state = (\n",
    "            train_spectroscopic_dataloader_state.set(\n",
    "                train_spectroscopic_dataloader.reset_index, jnp.array(True)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        t1_val = time.time()\n",
    "        val_step_time += t1_val - t0_val\n",
    "\n",
    "        epoch_train_loss = jnp.mean(jnp.array(epoch_train_loss), axis=0)\n",
    "        epoch_train_aux = jnp.mean(jnp.array(epoch_train_aux), axis=0)\n",
    "        epoch_val_loss = jnp.mean(jnp.array(epoch_val_loss), axis=0)\n",
    "        epoch_val_aux = jnp.mean(jnp.array(epoch_val_aux), axis=0)\n",
    "\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        train_aux.append(epoch_train_aux)\n",
    "        val_loss.append(epoch_val_loss)\n",
    "        val_aux.append(epoch_val_aux)\n",
    "\n",
    "        t1_epoch = time.time()\n",
    "        epoch_time += t1_epoch - t0_epoch\n",
    "        epoch_lr = lr_schedule(epoch)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch} - Time: {t1_epoch-t0_epoch:.2f} s - LR: {epoch_lr:.5e} - Train Loss: {epoch_train_loss:.5e} - Val Loss: {epoch_val_loss:.5e} - \"\n",
    "            + f\"TU Loss: {epoch_train_aux[0]:.5e} - TS Loss: {epoch_train_aux[6]:.5e} - TT Loss: {epoch_train_aux[7]:.5e} - \"\n",
    "            + f\"VU Loss: {epoch_val_aux[0]:.5e} - VS Loss: {epoch_val_aux[6]:.5e} - VT Loss: {epoch_val_aux[7]:.5e}\"\n",
    "        )\n",
    "\n",
    "        if len(val_loss) == 1 or epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_val_epoch = epoch\n",
    "            training.save(SAVE_DIR / \"best_pretrained_vae.pkl\", ssvae)\n",
    "            training.save(SAVE_DIR / \"best_pretrained_vae_state.pkl\", input_state)\n",
    "            training.save(\n",
    "                SAVE_DIR / \"best_pretrained_vae_optimizer_state\", optimizer_state\n",
    "            )\n",
    "\n",
    "        if (\n",
    "            cfg[\"training_config\"][\"use_early_stopping\"]\n",
    "            and epoch - best_val_epoch\n",
    "            > cfg[\"training_config\"][\"early_stopping_patience\"]\n",
    "        ):\n",
    "            print(f\"Early stopping at epoch {epoch}, setting model to best epoch\")\n",
    "            ssvae = training.load(SAVE_DIR / \"best_pretrained_vae.pkl\", ssvae)\n",
    "            input_state = training.load(\n",
    "                SAVE_DIR / \"best_pretrained_vae_state.pkl\", input_state\n",
    "            )\n",
    "            optimizer_state = training.load(\n",
    "                SAVE_DIR / \"final_pretrained_vae_optimizer_state\", optimizer_state\n",
    "            )\n",
    "            break\n",
    "\n",
    "    val_step_time = val_step_time / cfg[\"training_config\"][\"vae_epochs\"]\n",
    "    train_step_time = train_step_time / cfg[\"training_config\"][\"vae_epochs\"]\n",
    "    epoch_time = epoch_time / cfg[\"training_config\"][\"vae_epochs\"]\n",
    "    train_time = time.time() - t0\n",
    "\n",
    "    print(\n",
    "        f\"\\nTrain Time: {train_time:.2f} s - Train Step Time: {train_step_time:.2f} s - Val Step Time: {val_step_time:.2f} s - Epoch Time: {epoch_time:.2f} s - Best Epoch: {best_val_epoch}\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"\\n--------------------------------- SAVING PRE-TRAINED VAE ---------------------------------\\n\"\n",
    "    )\n",
    "\n",
    "    training.save(SAVE_DIR / \"final_pretrained_vae.pkl\", ssvae)\n",
    "    training.save(SAVE_DIR / \"final_pretrained_vae_state.pkl\", input_state)\n",
    "    training.save(\n",
    "        SAVE_DIR / \"final_pretrained_vae_optimizer_state\", optimizer_state\n",
    "    )\n",
    "\n",
    "    pretrained_vae_train_losses = jnp.asarray(train_loss)\n",
    "    pretrained_vae_val_losses = jnp.asarray(val_loss)\n",
    "\n",
    "    pretrained_vae_train_auxes = jnp.asarray(train_aux)\n",
    "    pretrained_vae_val_auxes = jnp.asarray(val_aux)\n",
    "\n",
    "    np.save(SAVE_DIR / \"pretrain_vae_train_losses.npy\", pretrained_vae_train_losses)\n",
    "    np.save(SAVE_DIR / \"pretrain_vae_val_losses.npy\", pretrained_vae_val_losses)\n",
    "    np.save(SAVE_DIR / \"pretrain_vae_train_auxes.npy\", pretrained_vae_train_auxes)\n",
    "    np.save(SAVE_DIR / \"pretrain_vae_val_auxes.npy\", pretrained_vae_val_auxes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg[\"training_config\"][\"pretrain_predictor\"]:\n",
    "\n",
    "    ###################################################################################\n",
    "    ################################# DATALOADERS #####################################\n",
    "    ###################################################################################\n",
    "\n",
    "    train_photo_dataloader_key, train_spec_dataloader_key, RNG_KEY = jr.split(\n",
    "        RNG_KEY, 3\n",
    "    )\n",
    "\n",
    "    (\n",
    "        train_photometric_dataloader,\n",
    "        train_photometric_dataloader_state,\n",
    "    ) = data.make_dataloader(\n",
    "        train_photo_dataset,\n",
    "        batch_size=5,\n",
    "        rng_key=train_photo_dataloader_key,\n",
    "        shuffle=cfg[\"data_config\"][\"shuffle\"],\n",
    "        drop_last=cfg[\"data_config\"][\"drop_last\"],\n",
    "    )\n",
    "\n",
    "    (\n",
    "        train_spectroscopic_dataloader,\n",
    "        train_spectroscopic_dataloader_state,\n",
    "    ) = data.make_dataloader(\n",
    "        train_spec_dataset,\n",
    "        batch_size=cfg[\"training_config\"][\"batch_size\"],\n",
    "        rng_key=train_spec_dataloader_key,\n",
    "        shuffle=cfg[\"data_config\"][\"shuffle\"],\n",
    "        drop_last=cfg[\"data_config\"][\"drop_last\"],\n",
    "    )\n",
    "\n",
    "    train_iterator = data.make_spectrophotometric_iterator(\n",
    "        train_photometric_dataloader,\n",
    "        train_spectroscopic_dataloader,\n",
    "        train_dataset_statistics,\n",
    "        resample_photometry=cfg[\"data_config\"][\"resample_photometry\"],\n",
    "    )\n",
    "\n",
    "    val_photo_dataloader_key, val_spec_dataloader_key, RNG_KEY = jr.split(\n",
    "        RNG_KEY, 3\n",
    "    )\n",
    "\n",
    "    (\n",
    "        val_photometric_dataloader,\n",
    "        val_photometric_dataloader_state,\n",
    "    ) = data.make_dataloader(\n",
    "        val_photo_dataset,\n",
    "        batch_size=cfg[\"training_config\"][\"batch_size\"],\n",
    "        rng_key=val_photo_dataloader_key,\n",
    "        shuffle=False,\n",
    "        drop_last=cfg[\"data_config\"][\"drop_last\"],\n",
    "    )\n",
    "\n",
    "    (\n",
    "        val_spectroscopic_dataloader,\n",
    "        val_spectroscopic_dataloader_state,\n",
    "    ) = data.make_dataloader(\n",
    "        val_spec_dataset,\n",
    "        batch_size=cfg[\"training_config\"][\"batch_size\"],\n",
    "        rng_key=val_spec_dataloader_key,\n",
    "        shuffle=False,\n",
    "        drop_last=cfg[\"data_config\"][\"drop_last\"],\n",
    "    )\n",
    "\n",
    "    val_iterator = data.make_spectrophotometric_iterator(\n",
    "        val_photometric_dataloader,\n",
    "        val_spectroscopic_dataloader,\n",
    "        val_dataset_statistics,\n",
    "        resample_photometry=cfg[\"data_config\"][\"resample_photometry\"],\n",
    "    )\n",
    "\n",
    "    filter_spec = nn.freeze_submodule(\n",
    "        ssvae, \"predictor\", filter_spec=filter_spec, inverse=True\n",
    "    )\n",
    "    filter_spec = nn.freeze_prior(ssvae, space=\"target\", filter_spec=filter_spec)\n",
    "    filter_spec = nn.freeze_submodule(ssvae, \"encoder\", filter_spec=filter_spec)\n",
    "    filter_spec = nn.freeze_submodule(ssvae, \"decoder\", filter_spec=filter_spec)\n",
    "    filter_spec = nn.freeze_submodule_inputs(\n",
    "        ssvae, \"decoder\", freeze_x=True, freeze_y=True, filter_spec=filter_spec\n",
    "    )\n",
    "\n",
    "    ssvae = nn.set_submodule_inference_mode(ssvae, \"predictor\", False)\n",
    "    ssvae = nn.set_submodule_inference_mode(ssvae, \"encoder\", True)\n",
    "    ssvae = nn.set_submodule_inference_mode(ssvae, \"decoder\", True)\n",
    "\n",
    "    if cfg[\"model_config\"][\"use_v2\"]:\n",
    "        filter_spec = nn.freeze_submodule_inputs(\n",
    "            ssvae,\n",
    "            \"predictor\",\n",
    "            freeze_x=True,\n",
    "            freeze_y=False,\n",
    "            filter_spec=filter_spec,\n",
    "            inverse=True,\n",
    "        )\n",
    "        ssvae = nn.init_submodule_inputs(\n",
    "            ssvae, \"predictor\", RNG_KEY, init_x=False, init_y=True, init_value=0.0\n",
    "        )\n",
    "    else:\n",
    "        filter_spec = nn.freeze_submodule_inputs(\n",
    "            ssvae, \"encoder\", freeze_x=True, freeze_y=True, filter_spec=filter_spec\n",
    "        )\n",
    "\n",
    "    lr_schedule = optax.warmup_cosine_decay_schedule(\n",
    "        cfg[\"training_config\"][\"final_lr\"],\n",
    "        cfg[\"training_config\"][\"init_lr\"],\n",
    "        cfg[\"training_config\"][\"warmup\"],\n",
    "        cfg[\"training_config\"][\"predictor_epochs\"]\n",
    "        - cfg[\"training_config\"][\"warmup\"],\n",
    "        cfg[\"training_config\"][\"final_lr\"],\n",
    "    )\n",
    "    optimizer = optax.adam(learning_rate=lr_schedule)\n",
    "    optimizer_state = optimizer.init(eqx.filter(ssvae, eqx.is_array))\n",
    "\n",
    "    loss_kwargs = {\n",
    "        \"alpha\": ALPHA,\n",
    "        \"missing_target_value\": cfg[\"data_config\"][\"missing_target_value\"],\n",
    "        \"vae_factor\": 0.0,\n",
    "        \"beta\": cfg[\"training_config\"][\"beta\"],\n",
    "        \"predictor_factor\": 0.0,\n",
    "        \"target_factor\": 1.0,\n",
    "        \"n_samples\": cfg[\"training_config\"][\"n_mc_samples\"],\n",
    "    }\n",
    "    pretrain_predictor_loss_fn = partial(training.ssvae_loss, **loss_kwargs)\n",
    "\n",
    "    _train_step = training.make_train_step(\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=pretrain_predictor_loss_fn,\n",
    "        filter_spec=filter_spec,\n",
    "    )\n",
    "\n",
    "    _val_step = training.make_eval_step(\n",
    "        loss_fn=pretrain_predictor_loss_fn,\n",
    "        filter_spec=filter_spec,\n",
    "    )\n",
    "\n",
    "    val_step_time = 0\n",
    "    train_step_time = 0\n",
    "    epoch_time = 0\n",
    "    best_val_loss = jnp.inf\n",
    "    best_val_epoch = -1\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def train_step(\n",
    "        ssvae, ssvae_state, optimizer_state, photo_dl_state, spec_dl_state, rng_key\n",
    "    ):\n",
    "\n",
    "        resampling_key, step_key = jr.split(rng_key)\n",
    "\n",
    "        (\n",
    "            x,\n",
    "            y,\n",
    "            photo_dl_state,\n",
    "            spec_dl_state,\n",
    "            _,\n",
    "            spectroscopic_reset_condition,\n",
    "        ) = train_iterator(\n",
    "            photo_dl_state,\n",
    "            spec_dl_state,\n",
    "            resampling_key,\n",
    "        )\n",
    "\n",
    "        end_of_split = jnp.all(spectroscopic_reset_condition)\n",
    "\n",
    "        ssvae, ssvae_state, optimizer_state, loss_value, loss_aux = _train_step(\n",
    "            x,\n",
    "            y,\n",
    "            step_key,\n",
    "            ssvae,\n",
    "            ssvae_state,\n",
    "            optimizer_state,\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            loss_value,\n",
    "            loss_aux,\n",
    "            ssvae,\n",
    "            ssvae_state,\n",
    "            optimizer_state,\n",
    "            photo_dl_state,\n",
    "            spec_dl_state,\n",
    "            end_of_split,\n",
    "        )\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def eval_step(\n",
    "        ssvae,\n",
    "        ssvae_state,\n",
    "        train_photo_dl_state,\n",
    "        train_spec_dl_state,\n",
    "        val_photo_dl_state,\n",
    "        val_spec_dl_state,\n",
    "        rng_key,\n",
    "    ):\n",
    "\n",
    "        train_resampling_key, val_resampling_key, rng_key = jr.split(rng_key, 3)\n",
    "        train_step_key, val_step_key = jr.split(rng_key)\n",
    "\n",
    "        (\n",
    "            x_val_split,\n",
    "            y_val_split,\n",
    "            val_photo_dl_state,\n",
    "            val_spec_dl_state,\n",
    "            photometric_reset_condition,\n",
    "            spectroscopic_reset_condition,\n",
    "        ) = val_iterator(\n",
    "            val_photo_dl_state,\n",
    "            val_spec_dl_state,\n",
    "            val_resampling_key,\n",
    "        )\n",
    "\n",
    "        (\n",
    "            x_train_split,\n",
    "            y_train_split,\n",
    "            train_photo_dl_state,\n",
    "            train_spec_dl_state,\n",
    "            _,\n",
    "            _,\n",
    "        ) = train_iterator(\n",
    "            train_photo_dl_state,\n",
    "            train_spec_dl_state,\n",
    "            train_resampling_key,\n",
    "        )\n",
    "\n",
    "        (\n",
    "            train_loss_value,\n",
    "            ssvae_state,\n",
    "            train_loss_aux,\n",
    "        ) = _val_step(\n",
    "            x_train_split,\n",
    "            y_train_split,\n",
    "            train_step_key,\n",
    "            ssvae,\n",
    "            ssvae_state,\n",
    "        )\n",
    "\n",
    "        val_loss_value, input_state, val_loss_aux = _val_step(\n",
    "            x_val_split,\n",
    "            y_val_split,\n",
    "            val_step_key,\n",
    "            ssvae,\n",
    "            ssvae_state,\n",
    "        )\n",
    "\n",
    "        end_of_val_split = jnp.all(spectroscopic_reset_condition)\n",
    "\n",
    "        return (\n",
    "            train_loss_value,\n",
    "            train_loss_aux,\n",
    "            val_loss_value,\n",
    "            val_loss_aux,\n",
    "            input_state,\n",
    "            train_photo_dl_state,\n",
    "            train_spec_dl_state,\n",
    "            val_photo_dl_state,\n",
    "            val_spec_dl_state,\n",
    "            end_of_val_split,\n",
    "        )\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    for epoch in range(cfg[\"training_config\"][\"predictor_epochs\"]):\n",
    "\n",
    "        end_of_train_split = False\n",
    "        end_of_val_split = False\n",
    "        end_of_prediction_split = False\n",
    "\n",
    "        train_batches = 0\n",
    "        val_batches = 0\n",
    "        epoch_train_loss = []\n",
    "        epoch_train_aux = []\n",
    "        epoch_val_loss = []\n",
    "        epoch_val_aux = []\n",
    "        epoch_val_target_means = []\n",
    "        epoch_val_target_stds = []\n",
    "\n",
    "        t0_epoch = time.time()\n",
    "\n",
    "        epoch_train_key, epoch_val_key, RNG_KEY = jr.split(RNG_KEY, 3)\n",
    "\n",
    "        while not end_of_train_split:\n",
    "\n",
    "            step_key, epoch_train_key = jr.split(epoch_train_key)\n",
    "\n",
    "            (\n",
    "                batch_train_loss,\n",
    "                batch_train_aux,\n",
    "                ssvae,\n",
    "                input_state,\n",
    "                optimizer_state,\n",
    "                train_photometric_dataloader_state,\n",
    "                train_spectroscopic_dataloader_state,\n",
    "                end_of_train_split,\n",
    "            ) = train_step(\n",
    "                ssvae,\n",
    "                input_state,\n",
    "                optimizer_state,\n",
    "                train_photometric_dataloader_state,\n",
    "                train_spectroscopic_dataloader_state,\n",
    "                step_key,\n",
    "            )\n",
    "\n",
    "            if end_of_train_split:\n",
    "                break\n",
    "\n",
    "            train_batches += 1\n",
    "\n",
    "        t1 = time.time()\n",
    "        train_step_time += t1 - t0_epoch\n",
    "\n",
    "        inference_ssvae = eqx.nn.inference_mode(ssvae)\n",
    "\n",
    "        t0_val = time.time()\n",
    "        while not end_of_val_split:\n",
    "\n",
    "            t0_single = time.time()\n",
    "\n",
    "            val_step_key, epoch_val_key = jr.split(epoch_val_key)\n",
    "\n",
    "            (\n",
    "                batch_train_loss,\n",
    "                batch_train_aux,\n",
    "                batch_val_loss,\n",
    "                batch_val_aux,\n",
    "                input_state,\n",
    "                train_photometric_dataloader_state,\n",
    "                train_spectroscopic_dataloader_state,\n",
    "                val_photometric_dataloader_state,\n",
    "                val_spectroscopic_dataloader_state,\n",
    "                end_of_val_split,\n",
    "            ) = eval_step(\n",
    "                inference_ssvae,\n",
    "                input_state,\n",
    "                train_photometric_dataloader_state,\n",
    "                train_spectroscopic_dataloader_state,\n",
    "                val_photometric_dataloader_state,\n",
    "                val_spectroscopic_dataloader_state,\n",
    "                val_step_key,\n",
    "            )\n",
    "\n",
    "            if end_of_val_split:\n",
    "                break\n",
    "\n",
    "            epoch_train_loss.append(batch_train_loss)\n",
    "            epoch_train_aux.append(batch_train_aux)\n",
    "            epoch_val_loss.append(batch_val_loss)\n",
    "            epoch_val_aux.append(batch_val_aux)\n",
    "\n",
    "            val_batches += 1\n",
    "            t1_single = time.time()\n",
    "\n",
    "        train_photometric_dataloader_state = train_photometric_dataloader_state.set(\n",
    "            train_photometric_dataloader.reset_index, jnp.array(True)\n",
    "        )\n",
    "        train_spectroscopic_dataloader_state = (\n",
    "            train_spectroscopic_dataloader_state.set(\n",
    "                train_spectroscopic_dataloader.reset_index, jnp.array(True)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        t1_val = time.time()\n",
    "        val_step_time += t1_val - t0_val\n",
    "\n",
    "        epoch_train_loss = jnp.mean(jnp.array(epoch_train_loss), axis=0)\n",
    "        epoch_train_aux = jnp.mean(jnp.array(epoch_train_aux), axis=0)\n",
    "        epoch_val_loss = jnp.mean(jnp.array(epoch_val_loss), axis=0)\n",
    "        epoch_val_aux = jnp.mean(jnp.array(epoch_val_aux), axis=0)\n",
    "\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        train_aux.append(epoch_train_aux)\n",
    "        val_loss.append(epoch_val_loss)\n",
    "        val_aux.append(epoch_val_aux)\n",
    "\n",
    "        t1_epoch = time.time()\n",
    "        epoch_time += t1_epoch - t0_epoch\n",
    "        epoch_lr = lr_schedule(epoch)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch} - Time: {t1_epoch-t0_epoch:.2f} s - LR: {epoch_lr:.5e} - Train Loss: {epoch_train_loss:.5e} - Val Loss: {epoch_val_loss:.5e} - \"\n",
    "            + f\"TU Loss: {epoch_train_aux[0]:.5e} - TS Loss: {epoch_train_aux[6]:.5e} - TT Loss: {epoch_train_aux[7]:.5e} - \"\n",
    "            + f\"VU Loss: {epoch_val_aux[0]:.5e} - VS Loss: {epoch_val_aux[6]:.5e} - VT Loss: {epoch_val_aux[7]:.5e}\"\n",
    "        )\n",
    "\n",
    "        if len(val_loss) == 1 or epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_val_epoch = epoch\n",
    "            training.save(SAVE_DIR / \"best_pretrained_predictor.pkl\", ssvae)\n",
    "            training.save(\n",
    "                SAVE_DIR / \"best_pretrained_predictor_state.pkl\", input_state\n",
    "            )\n",
    "            training.save(\n",
    "                SAVE_DIR / \"best_pretrained_predictor_optimizer_state\",\n",
    "                optimizer_state,\n",
    "            )\n",
    "\n",
    "        if (\n",
    "            cfg[\"training_config\"][\"use_early_stopping\"]\n",
    "            and epoch - best_val_epoch\n",
    "            > cfg[\"training_config\"][\"early_stopping_patience\"]\n",
    "        ):\n",
    "            print(f\"Early stopping at epoch {epoch}, setting model to best epoch\")\n",
    "            ssvae = training.load(SAVE_DIR / \"best_pretrained_predictor.pkl\", ssvae)\n",
    "            input_state = training.load(\n",
    "                SAVE_DIR / \"best_pretrained_predictor_state.pkl\", input_state\n",
    "            )\n",
    "            optimizer_state = training.load(\n",
    "                SAVE_DIR / \"final_pretrained_predictor_optimizer_state\",\n",
    "                optimizer_state,\n",
    "            )\n",
    "            break\n",
    "\n",
    "    val_step_time = val_step_time / cfg[\"training_config\"][\"predictor_epochs\"]\n",
    "    train_step_time = train_step_time / cfg[\"training_config\"][\"predictor_epochs\"]\n",
    "    epoch_time = epoch_time / cfg[\"training_config\"][\"predictor_epochs\"]\n",
    "    train_time = time.time() - t0\n",
    "\n",
    "    print(\n",
    "        f\"\\nTrain Time: {train_time:.2f} s - Train Step Time: {train_step_time:.2f} s - Val Step Time: {val_step_time:.2f} s - Epoch Time: {epoch_time:.2f} s - Best Epoch: {best_val_epoch}\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"\\n--------------------------------- SAVING PRE-TRAINED PREDICTOR ---------------------------------\\n\"\n",
    "    )\n",
    "\n",
    "    training.save(SAVE_DIR / \"final_pretrained_predictor.pkl\", ssvae)\n",
    "    training.save(SAVE_DIR / \"final_pretrained_predictor_state.pkl\", input_state)\n",
    "    training.save(\n",
    "        SAVE_DIR / \"final_pretrained_predictor_optimizer_state\", optimizer_state\n",
    "    )\n",
    "\n",
    "    pretrained_predictor_train_losses = jnp.asarray(train_loss)\n",
    "    pretrained_predictor_val_losses = jnp.asarray(val_loss)\n",
    "\n",
    "    pretrained_predictor_train_auxes = jnp.asarray(train_aux)\n",
    "    pretrained_predictor_val_auxes = jnp.asarray(val_aux)\n",
    "\n",
    "    np.save(\n",
    "        SAVE_DIR / \"pretrain_predictor_train_losses.npy\",\n",
    "        pretrained_predictor_train_losses,\n",
    "    )\n",
    "    np.save(\n",
    "        SAVE_DIR / \"pretrain_predictor_val_losses.npy\",\n",
    "        pretrained_predictor_val_losses,\n",
    "    )\n",
    "    np.save(\n",
    "        SAVE_DIR / \"pretrain_predictor_train_auxes.npy\",\n",
    "        pretrained_predictor_train_auxes,\n",
    "    )\n",
    "    np.save(\n",
    "        SAVE_DIR / \"pretrain_predictor_val_auxes.npy\",\n",
    "        pretrained_predictor_val_auxes,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg[\"training_config\"][\"train_full_model\"]:\n",
    "\n",
    "    ###################################################################################\n",
    "    ################################# DATALOADERS #####################################\n",
    "    ###################################################################################\n",
    "\n",
    "    train_photo_dataloader_key, train_spec_dataloader_key, RNG_KEY = jr.split(\n",
    "        RNG_KEY, 3\n",
    "    )\n",
    "\n",
    "    (\n",
    "        train_photometric_dataloader,\n",
    "        train_photometric_dataloader_state,\n",
    "    ) = data.make_dataloader(\n",
    "        train_photo_dataset,\n",
    "        batch_size=PHOTOMETRIC_BATCH_SIZE,\n",
    "        rng_key=train_photo_dataloader_key,\n",
    "        shuffle=cfg[\"data_config\"][\"shuffle\"],\n",
    "        drop_last=cfg[\"data_config\"][\"drop_last\"],\n",
    "    )\n",
    "\n",
    "    (\n",
    "        train_spectroscopic_dataloader,\n",
    "        train_spectroscopic_dataloader_state,\n",
    "    ) = data.make_dataloader(\n",
    "        train_spec_dataset,\n",
    "        batch_size=SPECTROSCOPIC_BATCH_SIZE,\n",
    "        rng_key=train_spec_dataloader_key,\n",
    "        shuffle=cfg[\"data_config\"][\"shuffle\"],\n",
    "        drop_last=cfg[\"data_config\"][\"drop_last\"],\n",
    "    )\n",
    "\n",
    "    train_iterator = data.make_spectrophotometric_iterator(\n",
    "        train_photometric_dataloader,\n",
    "        train_spectroscopic_dataloader,\n",
    "        train_dataset_statistics,\n",
    "        resample_photometry=cfg[\"data_config\"][\"resample_photometry\"],\n",
    "    )\n",
    "\n",
    "    val_photo_dataloader_key, val_spec_dataloader_key, RNG_KEY = jr.split(\n",
    "        RNG_KEY, 3\n",
    "    )\n",
    "\n",
    "    (\n",
    "        val_photometric_dataloader,\n",
    "        val_photometric_dataloader_state,\n",
    "    ) = data.make_dataloader(\n",
    "        val_photo_dataset,\n",
    "        batch_size=PHOTOMETRIC_BATCH_SIZE,\n",
    "        rng_key=val_photo_dataloader_key,\n",
    "        shuffle=False,\n",
    "        drop_last=cfg[\"data_config\"][\"drop_last\"],\n",
    "    )\n",
    "\n",
    "    (\n",
    "        val_spectroscopic_dataloader,\n",
    "        val_spectroscopic_dataloader_state,\n",
    "    ) = data.make_dataloader(\n",
    "        val_spec_dataset,\n",
    "        batch_size=SPECTROSCOPIC_BATCH_SIZE,\n",
    "        rng_key=val_spec_dataloader_key,\n",
    "        shuffle=False,\n",
    "        drop_last=cfg[\"data_config\"][\"drop_last\"],\n",
    "    )\n",
    "\n",
    "    val_iterator = data.make_spectrophotometric_iterator(\n",
    "        val_photometric_dataloader,\n",
    "        val_spectroscopic_dataloader,\n",
    "        val_dataset_statistics,\n",
    "        resample_photometry=cfg[\"data_config\"][\"resample_photometry\"],\n",
    "    )\n",
    "\n",
    "    filter_spec = nn.freeze_submodule(\n",
    "        ssvae, \"encoder\", filter_spec=filter_spec, inverse=True\n",
    "    )\n",
    "    filter_spec = nn.freeze_submodule(\n",
    "        ssvae, \"decoder\", filter_spec=filter_spec, inverse=True\n",
    "    )\n",
    "    filter_spec = nn.freeze_prior(\n",
    "        ssvae, space=\"target\", filter_spec=filter_spec, inverse=True\n",
    "    )\n",
    "    filter_spec = nn.freeze_submodule(\n",
    "        ssvae, \"predictor\", filter_spec=filter_spec, inverse=True\n",
    "    )\n",
    "    filter_spec = nn.freeze_submodule_inputs(\n",
    "        ssvae,\n",
    "        \"decoder\",\n",
    "        freeze_x=True,\n",
    "        freeze_y=True,\n",
    "        filter_spec=filter_spec,\n",
    "        inverse=True,\n",
    "    )\n",
    "\n",
    "    init_key, RNG_KEY = jr.split(RNG_KEY)\n",
    "    ssvae = nn.init_submodule_inputs(\n",
    "        ssvae, \"decoder\", init_key, init_x=True, init_y=True\n",
    "    )\n",
    "    ssvae = nn.set_submodule_inference_mode(ssvae, \"predictor\", False)\n",
    "    ssvae = nn.set_submodule_inference_mode(ssvae, \"encoder\", False)\n",
    "    ssvae = nn.set_submodule_inference_mode(ssvae, \"decoder\", False)\n",
    "\n",
    "    if cfg[\"model_config\"][\"use_v2\"]:\n",
    "        filter_spec = nn.freeze_submodule_inputs(\n",
    "            ssvae,\n",
    "            \"predictor\",\n",
    "            freeze_x=True,\n",
    "            freeze_y=True,\n",
    "            filter_spec=filter_spec,\n",
    "            inverse=True,\n",
    "        )\n",
    "    else:\n",
    "        init_key, RNG_KEY = jr.split(RNG_KEY)\n",
    "        filter_spec = nn.freeze_submodule_inputs(\n",
    "            ssvae,\n",
    "            \"encoder\",\n",
    "            freeze_x=True,\n",
    "            freeze_y=True,\n",
    "            filter_spec=filter_spec,\n",
    "            inverse=True,\n",
    "        )\n",
    "        ssvae = nn.init_submodule_inputs(\n",
    "            ssvae, \"encoder\", init_key, init_x=True, init_y=True\n",
    "        )\n",
    "\n",
    "    lr_schedule = optax.warmup_cosine_decay_schedule(\n",
    "        cfg[\"training_config\"][\"final_lr\"],\n",
    "        cfg[\"training_config\"][\"init_lr\"],\n",
    "        cfg[\"training_config\"][\"warmup\"],\n",
    "        cfg[\"training_config\"][\"full_model_epochs\"]\n",
    "        - cfg[\"training_config\"][\"warmup\"],\n",
    "        cfg[\"training_config\"][\"final_lr\"],\n",
    "    )\n",
    "    optimizer = optax.adam(learning_rate=lr_schedule)\n",
    "    optimizer_state = optimizer.init(eqx.filter(ssvae, eqx.is_array))\n",
    "\n",
    "    loss_kwargs = {\n",
    "        \"alpha\": ALPHA,\n",
    "        \"missing_target_value\": cfg[\"data_config\"][\"missing_target_value\"],\n",
    "        \"vae_factor\": 1.0,\n",
    "        \"beta\": cfg[\"training_config\"][\"beta\"],\n",
    "        \"predictor_factor\": 1.0,\n",
    "        \"target_factor\": 1.0,\n",
    "        \"n_samples\": cfg[\"training_config\"][\"n_mc_samples\"],\n",
    "    }\n",
    "    full_loss_fn = partial(training.ssvae_loss, **loss_kwargs)\n",
    "\n",
    "    _train_step = training.make_train_step(\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=full_loss_fn,\n",
    "        filter_spec=filter_spec,\n",
    "    )\n",
    "\n",
    "    _val_step = training.make_eval_step(\n",
    "        loss_fn=full_loss_fn,\n",
    "        filter_spec=filter_spec,\n",
    "    )\n",
    "\n",
    "    val_step_time = 0\n",
    "    train_step_time = 0\n",
    "    prediction_step_time = 0\n",
    "    epoch_time = 0\n",
    "    best_val_loss = jnp.inf\n",
    "    best_val_epoch = -1\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def train_step(\n",
    "        ssvae, ssvae_state, optimizer_state, photo_dl_state, spec_dl_state, rng_key\n",
    "    ):\n",
    "\n",
    "        resampling_key, step_key = jr.split(rng_key)\n",
    "\n",
    "        (\n",
    "            x,\n",
    "            y,\n",
    "            photo_dl_state,\n",
    "            spec_dl_state,\n",
    "            _,\n",
    "            spectroscopic_reset_condition,\n",
    "        ) = train_iterator(\n",
    "            photo_dl_state,\n",
    "            spec_dl_state,\n",
    "            resampling_key,\n",
    "        )\n",
    "\n",
    "        end_of_split = jnp.all(spectroscopic_reset_condition)\n",
    "\n",
    "        ssvae, ssvae_state, optimizer_state, loss_value, loss_aux = _train_step(\n",
    "            x,\n",
    "            y,\n",
    "            step_key,\n",
    "            ssvae,\n",
    "            ssvae_state,\n",
    "            optimizer_state,\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            loss_value,\n",
    "            loss_aux,\n",
    "            ssvae,\n",
    "            ssvae_state,\n",
    "            optimizer_state,\n",
    "            photo_dl_state,\n",
    "            spec_dl_state,\n",
    "            end_of_split,\n",
    "        )\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def eval_step(\n",
    "        ssvae,\n",
    "        ssvae_state,\n",
    "        train_photo_dl_state,\n",
    "        train_spec_dl_state,\n",
    "        val_photo_dl_state,\n",
    "        val_spec_dl_state,\n",
    "        rng_key,\n",
    "    ):\n",
    "\n",
    "        train_resampling_key, val_resampling_key, rng_key = jr.split(rng_key, 3)\n",
    "        train_step_key, val_step_key = jr.split(rng_key)\n",
    "\n",
    "        (\n",
    "            x_val_split,\n",
    "            y_val_split,\n",
    "            val_photo_dl_state,\n",
    "            val_spec_dl_state,\n",
    "            photometric_reset_condition,\n",
    "            spectroscopic_reset_condition,\n",
    "        ) = val_iterator(\n",
    "            val_photo_dl_state,\n",
    "            val_spec_dl_state,\n",
    "            val_resampling_key,\n",
    "        )\n",
    "\n",
    "        (\n",
    "            x_train_split,\n",
    "            y_train_split,\n",
    "            train_photo_dl_state,\n",
    "            train_spec_dl_state,\n",
    "            _,\n",
    "            _,\n",
    "        ) = train_iterator(\n",
    "            train_photo_dl_state,\n",
    "            train_spec_dl_state,\n",
    "            train_resampling_key,\n",
    "        )\n",
    "\n",
    "        (\n",
    "            train_loss_value,\n",
    "            ssvae_state,\n",
    "            train_loss_aux,\n",
    "        ) = _val_step(\n",
    "            x_train_split,\n",
    "            y_train_split,\n",
    "            train_step_key,\n",
    "            ssvae,\n",
    "            ssvae_state,\n",
    "        )\n",
    "\n",
    "        val_loss_value, input_state, val_loss_aux = _val_step(\n",
    "            x_val_split,\n",
    "            y_val_split,\n",
    "            val_step_key,\n",
    "            ssvae,\n",
    "            ssvae_state,\n",
    "        )\n",
    "\n",
    "        end_of_val_split = jnp.all(spectroscopic_reset_condition)\n",
    "\n",
    "        return (\n",
    "            train_loss_value,\n",
    "            train_loss_aux,\n",
    "            val_loss_value,\n",
    "            val_loss_aux,\n",
    "            input_state,\n",
    "            train_photo_dl_state,\n",
    "            train_spec_dl_state,\n",
    "            val_photo_dl_state,\n",
    "            val_spec_dl_state,\n",
    "            end_of_val_split,\n",
    "        )\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    for epoch in range(cfg[\"training_config\"][\"full_model_epochs\"]):\n",
    "\n",
    "        end_of_train_split = False\n",
    "        end_of_val_split = False\n",
    "        end_of_prediction_split = False\n",
    "\n",
    "        train_batches = 0\n",
    "        val_batches = 0\n",
    "        epoch_train_loss = []\n",
    "        epoch_train_aux = []\n",
    "        epoch_val_loss = []\n",
    "        epoch_val_aux = []\n",
    "        epoch_val_target_means = []\n",
    "        epoch_val_target_stds = []\n",
    "\n",
    "        t0_epoch = time.time()\n",
    "\n",
    "        epoch_train_key, epoch_val_key, RNG_KEY = jr.split(RNG_KEY, 3)\n",
    "\n",
    "        while not end_of_train_split:\n",
    "\n",
    "            step_key, epoch_train_key = jr.split(epoch_train_key)\n",
    "\n",
    "            (\n",
    "                batch_train_loss,\n",
    "                batch_train_aux,\n",
    "                ssvae,\n",
    "                input_state,\n",
    "                optimizer_state,\n",
    "                train_photometric_dataloader_state,\n",
    "                train_spectroscopic_dataloader_state,\n",
    "                end_of_train_split,\n",
    "            ) = train_step(\n",
    "                ssvae,\n",
    "                input_state,\n",
    "                optimizer_state,\n",
    "                train_photometric_dataloader_state,\n",
    "                train_spectroscopic_dataloader_state,\n",
    "                step_key,\n",
    "            )\n",
    "\n",
    "            if end_of_train_split:\n",
    "                break\n",
    "\n",
    "            train_batches += 1\n",
    "\n",
    "        t1 = time.time()\n",
    "        train_step_time += t1 - t0_epoch\n",
    "\n",
    "        inference_ssvae = eqx.nn.inference_mode(ssvae)\n",
    "\n",
    "        t0_val = time.time()\n",
    "        while not end_of_val_split:\n",
    "\n",
    "            t0_single = time.time()\n",
    "\n",
    "            val_step_key, epoch_val_key = jr.split(epoch_val_key)\n",
    "\n",
    "            (\n",
    "                batch_train_loss,\n",
    "                batch_train_aux,\n",
    "                batch_val_loss,\n",
    "                batch_val_aux,\n",
    "                input_state,\n",
    "                train_photometric_dataloader_state,\n",
    "                train_spectroscopic_dataloader_state,\n",
    "                val_photometric_dataloader_state,\n",
    "                val_spectroscopic_dataloader_state,\n",
    "                end_of_val_split,\n",
    "            ) = eval_step(\n",
    "                inference_ssvae,\n",
    "                input_state,\n",
    "                train_photometric_dataloader_state,\n",
    "                train_spectroscopic_dataloader_state,\n",
    "                val_photometric_dataloader_state,\n",
    "                val_spectroscopic_dataloader_state,\n",
    "                val_step_key,\n",
    "            )\n",
    "\n",
    "            if end_of_val_split:\n",
    "                break\n",
    "\n",
    "            epoch_train_loss.append(batch_train_loss)\n",
    "            epoch_train_aux.append(batch_train_aux)\n",
    "            epoch_val_loss.append(batch_val_loss)\n",
    "            epoch_val_aux.append(batch_val_aux)\n",
    "\n",
    "            val_batches += 1\n",
    "            t1_single = time.time()\n",
    "\n",
    "        train_photometric_dataloader_state = train_photometric_dataloader_state.set(\n",
    "            train_photometric_dataloader.reset_index, jnp.array(True)\n",
    "        )\n",
    "        train_spectroscopic_dataloader_state = (\n",
    "            train_spectroscopic_dataloader_state.set(\n",
    "                train_spectroscopic_dataloader.reset_index, jnp.array(True)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        t1_val = time.time()\n",
    "        val_step_time += t1_val - t0_val\n",
    "\n",
    "        epoch_train_loss = jnp.mean(jnp.array(epoch_train_loss), axis=0)\n",
    "        epoch_train_aux = jnp.mean(jnp.array(epoch_train_aux), axis=0)\n",
    "        epoch_val_loss = jnp.mean(jnp.array(epoch_val_loss), axis=0)\n",
    "        epoch_val_aux = jnp.mean(jnp.array(epoch_val_aux), axis=0)\n",
    "\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        train_aux.append(epoch_train_aux)\n",
    "        val_loss.append(epoch_val_loss)\n",
    "        val_aux.append(epoch_val_aux)\n",
    "\n",
    "        t1_epoch = time.time()\n",
    "        epoch_time += t1_epoch - t0_epoch\n",
    "        epoch_lr = lr_schedule(epoch)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch} - Time: {t1_epoch-t0_epoch:.2f} s - LR: {epoch_lr:.5e} - Train Loss: {epoch_train_loss:.5e} - Val Loss: {epoch_val_loss:.5e} - \"\n",
    "            + f\"TU Loss: {epoch_train_aux[0]:.5e} - TS Loss: {epoch_train_aux[6]:.5e} - TT Loss: {epoch_train_aux[7]:.5e} - \"\n",
    "            + f\"VU Loss: {epoch_val_aux[0]:.5e} - VS Loss: {epoch_val_aux[6]:.5e} - VT Loss: {epoch_val_aux[7]:.5e}\"\n",
    "        )\n",
    "\n",
    "        if len(val_loss) == 1 or epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_val_epoch = epoch\n",
    "            training.save(SAVE_DIR / \"best_model.pkl\", ssvae)\n",
    "            training.save(SAVE_DIR / \"best_model_state.pkl\", input_state)\n",
    "            training.save(SAVE_DIR / \"best_model_optimizer_state\", optimizer_state)\n",
    "\n",
    "        if (\n",
    "            cfg[\"training_config\"][\"use_early_stopping\"]\n",
    "            and epoch - best_val_epoch\n",
    "            > cfg[\"training_config\"][\"early_stopping_patience\"]\n",
    "        ):\n",
    "            print(f\"Early stopping at epoch {epoch}, setting model to best epoch\")\n",
    "            ssvae = training.load(SAVE_DIR / \"best_model.pkl\", ssvae)\n",
    "            input_state = training.load(\n",
    "                SAVE_DIR / \"best_model_state.pkl\", input_state\n",
    "            )\n",
    "            optimizer_state = training.load(\n",
    "                SAVE_DIR / \"final_model_optimizer_state\", optimizer_state\n",
    "            )\n",
    "            break\n",
    "\n",
    "    val_step_time = val_step_time / cfg[\"training_config\"][\"full_model_epochs\"]\n",
    "    train_step_time = train_step_time / cfg[\"training_config\"][\"full_model_epochs\"]\n",
    "    epoch_time = epoch_time / cfg[\"training_config\"][\"full_model_epochs\"]\n",
    "    train_time = time.time() - t0\n",
    "\n",
    "    print(\n",
    "        f\"\\nTrain Time: {train_time:.2f} s - Train Step Time: {train_step_time:.2f} s - Val Step Time: {val_step_time:.2f} s - Epoch Time: {epoch_time:.2f} s - Best Epoch: {best_val_epoch}\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"\\n--------------------------------- SAVING FULL MODEL ---------------------------------\\n\"\n",
    "    )\n",
    "\n",
    "    training.save(SAVE_DIR / \"final_model.pkl\", ssvae)\n",
    "    training.save(SAVE_DIR / \"final_model_state.pkl\", input_state)\n",
    "    training.save(SAVE_DIR / \"final_model_optimizer_state\", optimizer_state)\n",
    "\n",
    "    model_predictor_train_losses = jnp.asarray(train_loss)\n",
    "    model_predictor_val_losses = jnp.asarray(val_loss)\n",
    "\n",
    "    model_predictor_train_auxes = jnp.asarray(train_aux)\n",
    "    model_predictor_val_auxes = jnp.asarray(val_aux)\n",
    "\n",
    "    np.save(SAVE_DIR / \"full_train_losses.npy\", model_predictor_train_losses)\n",
    "    np.save(SAVE_DIR / \"full_val_losses.npy\", model_predictor_val_losses)\n",
    "    np.save(SAVE_DIR / \"full_train_auxes.npy\", model_predictor_train_auxes)\n",
    "    np.save(SAVE_DIR / \"full_val_auxes.npy\", model_predictor_val_auxes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaez",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
